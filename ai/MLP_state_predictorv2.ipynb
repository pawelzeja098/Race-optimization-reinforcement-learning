{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08a54cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import xgboost as xgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# from envs.filtr_json_from_race import load_from_db\n",
    "import sqlite3\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e6243",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaceModel(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super().__init__()\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(input_size,128), nn.ReLU(),\n",
    "            nn.Linear(128,128), nn.ReLU()\n",
    "        )\n",
    "        self.out = nn.Linear(128,output_size)     \n",
    "        \n",
    "        self.scaler_X = None\n",
    "        self.scaler_Y = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.shared(x)\n",
    "        return self.out(h)\n",
    "    \n",
    "    def set_scalers(self, scaler_X, scaler_Y):\n",
    "        self.scaler_X = scaler_X\n",
    "        self.scaler_Y = scaler_Y\n",
    "    \n",
    "    def scale_input(self, X_grouped,Y_grouped):\n",
    "         # --- Continous and discrete feature indices ---\n",
    "        cont_indices_x = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]     # continuous\n",
    "        cont_indices_y = [0,1,2,3,4,5,6,7,8,9,10,11]          # continuous\n",
    "    \n",
    "\n",
    "        # --- Scale continuous features ---\n",
    "        all_X_cont = np.vstack([x[:, cont_indices_x] for x in X_grouped])\n",
    "        all_Y_cont = np.vstack([y[:, cont_indices_y] for y in Y_grouped])\n",
    "        self.scaler_X = StandardScaler().fit(all_X_cont)\n",
    "        self.scaler_Y = StandardScaler().fit(all_Y_cont)\n",
    "\n",
    "        # Scale X and Y for continuous features\n",
    "        X_scaled_grouped = []\n",
    "        Y_scaled_grouped = []\n",
    "        for x_seq, y_seq in zip(X_grouped, Y_grouped):\n",
    "            x_scaled = np.array(x_seq)\n",
    "            x_scaled[:, cont_indices_x] = self.scaler_X.transform(x_seq[:, cont_indices_x])\n",
    "            X_scaled_grouped.append(x_scaled)\n",
    "\n",
    "            y_scaled = np.array(y_seq)\n",
    "            y_scaled[:, cont_indices_y] = self.scaler_Y.transform(y_seq[:, cont_indices_y])\n",
    "            Y_scaled_grouped.append(y_scaled)\n",
    "\n",
    "        # Conversion to torch tensors\n",
    "        X_t = [torch.tensor(x, dtype=torch.float32) for x in X_scaled_grouped]\n",
    "        Y_cont_t = [torch.tensor(y[:, cont_indices_y], dtype=torch.float32) for y in Y_scaled_grouped]\n",
    "\n",
    "        return X_t, Y_cont_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6057ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_db():\n",
    "    \n",
    "    \"\"\"\n",
    "    Load data so that each race is a separate sequence:\n",
    "    X = [ [state1_race1, state2_race1, ...], [state1_race2, ...] ]\n",
    "    Y = [ [next1_race1, next2_race1, ...], ... ]\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(\n",
    "        \"E:/pracadyp/Race-optimization-reinforcement-learning/data/db_states_for_regress/race_data_states.db\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT race_id, states_json FROM races ORDER BY race_id\")\n",
    "    rows = cursor.fetchall()\n",
    "    conn.close()\n",
    "\n",
    "    X_grouped, Y_grouped = [], []\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for race_id, states_json in rows:\n",
    "        states = json.loads(states_json)\n",
    "        data.append(states)\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2bbce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_single_step(X_grouped, Y_grouped):\n",
    "    X_single, Y_single = [], []\n",
    "    for X_race, Y_race in zip(X_grouped, Y_grouped):\n",
    "        for t in range(len(X_race)):\n",
    "            X_single.append(X_race[t])\n",
    "            Y_single.append(Y_race[t])\n",
    "    return X_single, Y_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a19c170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b536dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_single' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 58\u001b[39m\n\u001b[32m     52\u001b[39m model = RaceModel(input_size, output_size).to(device)\n\u001b[32m     54\u001b[39m X_scaled, Y_scaled = model.scale_input(X, Y)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m X_train_tensor = torch.tensor(\u001b[43mX_train_single\u001b[49m, dtype=torch.float32).to(device)\n\u001b[32m     59\u001b[39m Y_train_tensor = torch.tensor(Y_train_single, dtype=torch.float32).to(device)\n\u001b[32m     60\u001b[39m X_test_tensor = torch.tensor(X_test_single, dtype=torch.float32).to(device)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train_single' is not defined"
     ]
    }
   ],
   "source": [
    "X, Y = load_data_from_db()\n",
    "\n",
    "input_size = X[0].shape[1]\n",
    "output_size = Y[0].shape[1]\n",
    "loo = LeaveOneOut()\n",
    "all_fold_train = []\n",
    "all_fold_test = []\n",
    "all_fold_r2_test = []\n",
    "for fold, (train_idx, test_idx) in enumerate(loo.split(X)):\n",
    "    \n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    model = RaceModel(input_size, output_size).to(device)\n",
    "\n",
    "    X_scaled, Y_scaled = model.scale_input(X, Y)\n",
    "\n",
    "    X_train_single, Y_train_single = make_single_step([X_scaled[i] for i in train_idx],\n",
    "                                                      [Y_scaled[i] for i in train_idx])\n",
    "    X_test_single, Y_test_single = make_single_step([X_scaled[i] for i in test_idx],\n",
    "                                                    [Y_scaled[i] for i in test_idx])\n",
    "    \n",
    "    X_train_tensor = torch.tensor(X_train_single, dtype=torch.float32).to(device)\n",
    "    Y_train_tensor = torch.tensor(Y_train_single, dtype=torch.float32).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test_single, dtype=torch.float32).to(device)\n",
    "    Y_test_tensor = torch.tensor(Y_test_single, dtype=torch.float32).to(device)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=4e-5)\n",
    "    loss_cont = nn.MSELoss()\n",
    "    loss_cat  = nn.CrossEntropyLoss()\n",
    "\n",
    "    fold_train_losses = []\n",
    "    fold_test_losses = []\n",
    "\n",
    "    print(f\"Fold {fold+1}\")\n",
    "    X_train = [X_t[i] for i in train_idx]\n",
    "    X_test  = [X_t[i] for i in test_idx]\n",
    "    Y_cont_train = [Y_t[i] for i in train_idx]\n",
    "    Y_cont_test  = [Y_t[i] for i in test_idx]\n",
    " \n",
    "\n",
    "    X_train = [x.to(device) for x in X_train]\n",
    "    Y_train = [y.to(device) for y in Y_train]\n",
    "    \n",
    "\n",
    "    X_test = [x.to(device) for x in X_test]\n",
    "    Y_test = [y.to(device) for y in Y_test]   \n",
    "    \n",
    "    \n",
    "    n_epochs = 750\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.0\n",
    "        model.train()\n",
    "        for x_seq, y_seq in zip(X_train, Y_train): # y_cat_seq, Y_cat_train):\n",
    "           \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(x_seq) # continuous and list of categorical predictions , cat_preds\n",
    "\n",
    "            loss = loss_cont(y_pred, y_seq)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_train_loss = total_loss / len(X_train)\n",
    "\n",
    "        total_test_loss = 0.0\n",
    "        model.eval()\n",
    "        all_mse = []\n",
    "\n",
    "        y_true_all = []\n",
    "        y_pred_all = []\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x_seq, y_seq in zip(X_test, Y_test): #,y_cat_seq, Y_cat_test):\n",
    "                x_seq = x_seq.to(device)\n",
    "                y_seq = y_seq.to(device)\n",
    "                # y_cat_seq = [y.to(device) for y in y_cat_seq]\n",
    "\n",
    "                cont_pred = model(x_seq) #, cat_preds = model(x_seq)\n",
    "\n",
    "                loss = loss_cont(cont_pred, y_seq)\n",
    "\n",
    "                total_test_loss += loss.item()\n",
    "                \n",
    "\n",
    "        if epoch == n_epochs-1:\n",
    "            all_r2_per_output = []\n",
    "            with torch.no_grad():\n",
    "                for x_seq, y_seq in zip(X_test, Y_test):\n",
    "                    y_pred = model(x_seq.to(device))\n",
    "                    y_seq_orig = model.scaler_Y.inverse_transform(y_seq.cpu().numpy())\n",
    "                    y_pred_orig = model.scaler_Y.inverse_transform(y_pred.cpu().numpy())\n",
    "                    y_true_all.append(y_seq_orig)\n",
    "                    y_pred_all.append(y_pred_orig)\n",
    "\n",
    "                    r2s = [r2_score(y_seq_orig[:, i], y_pred_orig[:, i]) for i in range(y_seq_orig.shape[1])]\n",
    "                    all_r2_per_output.append(r2s)\n",
    "\n",
    "            avg_r2_per_output = np.mean(all_r2_per_output, axis=0)\n",
    "            print(\"Avg R2 per output:\", \"{:.4f}\".format(avg_r2_per_output))\n",
    "            print(\"Mean R2:\", \"{:.4f}\".format(np.mean(avg_r2_per_output)))\n",
    "\n",
    "        avg_test_loss = total_test_loss / len(X_test)\n",
    "     \n",
    "        \n",
    "        fold_train_losses.append(avg_train_loss)\n",
    "        fold_test_losses.append(avg_test_loss)\n",
    "\n",
    "    \n",
    "        \n",
    "    all_fold_train.append(fold_train_losses)\n",
    "    all_fold_test.append(fold_test_losses)\n",
    "\n",
    "   \n",
    "\n",
    "for fold in range(len(all_fold_train)):\n",
    "    plt.figure()\n",
    "    plt.plot(all_fold_train[fold], label='Train')\n",
    "    plt.plot(all_fold_test[fold], label='Test')\n",
    "    plt.title(f'Fold {fold+1}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RsOPT_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

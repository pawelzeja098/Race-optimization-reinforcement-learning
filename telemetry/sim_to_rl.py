import numpy as np
import socket
import threading
import json
from queue import Queue, Empty
import time
from torch.distributions import Categorical
import torch
from datetime import datetime
import os


def run_rl_agent(client, model, scaler_X_min_max, scaler_X_robust, usage_multiplier=3.0, save_dir="telemetry_logs"):
    print("Start wƒÖtku RL - tryb: Scoring -> Next Telem")

    # Zmienna-magazyn: tu trzymamy Scoring, kt√≥ry czeka na swojƒÖ parƒô (Telemetriƒô)
    pending_scoring = None
    
    # Dla logowania: magazyn dla ka≈ºdego scoring (niezale≈ºnie od sektora)
    last_scoring = None
    
    # Do wykrywania zmiany sektora
    prev_sector = -1
    
    # Listy do zbierania scoring i telemetry OSOBNO
    scoring_log = []
    telemetry_log = []
    record_counter = 0
    scoring_counter = 0  # Licznik wszystkich scoring√≥w (do filtrowania co 2)
    
    # Utw√≥rz katalog na logi
    os.makedirs(save_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    scoring_file = os.path.join(save_dir, f"race_scoring_{timestamp}.json")
    telemetry_file = os.path.join(save_dir, f"race_telemetry_{timestamp}.json")
    print(f"üìä Zapisywanie danych do:")
    print(f"   Scoring:    {scoring_file}")
    print(f"   Telemetry:  {telemetry_file}")

    try:
        while client.running:
            try:
                # Czekamy na dane (nie blokujemy procesora na 100%, ale reagujemy natychmiast)
                data = client.queue.get(timeout=1.0)
            except Empty:
                continue

            msg_type = data.get("Type")

            # --- 1. Przysz≈Ço SCORING ---
            if msg_type == "ScoringInfoV01":
            
                # Pobieramy dane gracza
                vehicles = data.get("mVehicles", [])
                # Szybkie szukanie gracza
                player = next((v for v in vehicles if v.get("mIsPlayer")), None)

                if not player:
                    continue
                
                # ========================================
                # LOGOWANIE: Zapisz CO DRUGI scoring
                # ========================================
                scoring_counter += 1
                if scoring_counter % 2 == 0:  # Co drugi scoring
                    last_scoring = data.copy()
                    last_scoring["mVehicles"] = [player]  # Tylko gracz, nie wszystkie pojazdy
                    record_counter += 1
                    scoring_record = {
                        "record_id": record_counter,
                        "timestamp": datetime.now().isoformat(),
                        "data": last_scoring
                    }
                    scoring_log.append(scoring_record)
                # ========================================
                
                curr_sector = player["mSector"]
                
                # Debug: Poka≈º zmianƒô sektora
                if curr_sector != prev_sector:
                    print(f"üèÅ Sektor: {prev_sector} ‚Üí {curr_sector} (Okr: {player['mTotalLaps']})")
            
                # WARUNEK WYZWOLENIA:
                # W≈Ça≈õnie wjechali≈õmy w sektor 2 (a wcze≈õniej byli≈õmy w innym, np. 1)
                # I NIE mamy ju≈º oczekujƒÖcego scoringu (≈ºeby nie nadpisaƒá go dwa razy w tej samej sekundzie)
                if curr_sector == 0 and prev_sector == 2 and pending_scoring is None:
                    print(f"\n{'='*60}")
                    print(f"‚ö° TRIGGER! Sektor 0 po 2 - OkrƒÖ≈ºenie {player['mTotalLaps']}")
                    print(f"{'='*60}")
                    
                    # Przygotowujemy dane scoringu pod extrakcjƒô
                    data["mVehicles"] = [player]
                    pending_scoring = data

                # Aktualizujemy historiƒô sektora
                prev_sector = curr_sector

            # --- 2. Przysz≈Ço TELEM ---
            elif msg_type == "TelemInfoV01":
                
                # ========================================
                # LOGOWANIE: Zapisz TYLKO PIERWSZƒÑ telemetry po ka≈ºdym scoringu
                # ========================================
                if last_scoring is not None:
                    telemetry_record = {
                        "record_id": record_counter,  # Ten sam co scoring
                        "timestamp": datetime.now().isoformat(),
                        "data": data
                    }
                    telemetry_log.append(telemetry_record)
                    last_scoring = None  # Reset - nastƒôpne telemetrie do nowego scoringu
                    
                    # Auto-zapis co 20 par
                    if record_counter % 20 == 0:
                        with open(scoring_file, 'w') as f:
                            json.dump(scoring_log, f, indent=2)
                        with open(telemetry_file, 'w') as f:
                            json.dump(telemetry_log, f, indent=2)
                    
                    if record_counter % 100 == 0:
                        print(f"üíæ [{record_counter}] Auto-zapis: {len(scoring_log)} par")
                # ========================================
                
                # Czy mamy oczekujƒÖcy Scoring? (Czy "zapadka" jest ustawiona?)
                if pending_scoring is not None:
                    # TO JEST TEN MOMENT - Pierwsza telemetria po scoringu
                    
                    try:
                        # Dodajemy multiplier do telemetrii
                        data["multiplier"] = usage_multiplier
                        
                        # 1. ≈ÅƒÖczymy zapamiƒôtany Scoring z bie≈ºƒÖcƒÖ TelemetriƒÖ
                        raw_state = extract_state(data, pending_scoring)
                        
                        # 2. Skalowanie
                        input_vector = preprocess_data(np.array(raw_state), scaler_X_min_max, scaler_X_robust)
                        
                    
                        tensor_in = torch.FloatTensor(input_vector).unsqueeze(0)
                        
                        with torch.no_grad():
                            print("Obliczam akcjƒô modelu...")
                            # Zak≈Çadam, ≈ºe model zwraca logity lub akcje
                            prediction = select_action_deterministic(model, input_vector)
                            
                            wheels = ["Soft", "Medium", "Hard", "Wet"]
                        
                            print("Na podstawie stanu:")
                            print("Ilo≈õƒá paliwa:" , raw_state[0])
                            print("Postƒôp wy≈õcigu:", raw_state[1])
                            print("Zu≈ºycie opon LF:", raw_state[2])
                            print("Zu≈ºycie opon RF:", raw_state[3])
                            print("Zu≈ºycie opon LR:", raw_state[4])
                            print("Zu≈ºycie opon RR:", raw_state[5])
                            print("Wilgotno≈õƒá toru:", raw_state[6])
                            print("Natƒô≈ºenie deszczu:", raw_state[7])
                            print("Uszkodzenia nadwozia:", raw_state[8:16])
                            print("Liczba okrƒÖ≈ºe≈Ñ:", raw_state[16])
                            print("Liczba pit-stop√≥w:", raw_state[17])
                            print("Typ opon:", wheels[int(raw_state[18])])
                            print("Mno≈ºnik zu≈ºycia:", raw_state[19])
                            print("Temperatura opon LF:", raw_state[20])
                            print("Temperatura opon RF:", raw_state[21])
                            print("Temperatura opon LR:", raw_state[22])
                            print("Temperatura opon RR:", raw_state[23])
                            print("Temperatura otoczenia:", raw_state[24])
                            print("Temperatura toru:", raw_state[25])
                            print("Przewidywany czas zako≈Ñczenia wy≈õcigu:", raw_state[26])

                            if prediction[0] == 1:
                                print("Decyzja: Wjazd na pit-stop")

                            
                            print(f"Action: {action_to_string(prediction)}")
                        

                    except Exception as e:
                        print(f"B≈ÇƒÖd w obliczeniach RL: {e}")
                    
                
                    pending_scoring = None   

    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Przerwano przez u≈ºytkownika (Ctrl+C)")
    
    finally:
        # ========================================
        # ZAPIS KO≈ÉCOWY - wykonuje siƒô ZAWSZE
        # ========================================
        print(f"\n{'='*60}")
        print(f"üèÅ Koniec sesji - zapisujƒô dane ko≈Ñcowe...")
        if scoring_log or telemetry_log:
            with open(scoring_file, 'w') as f:
                json.dump(scoring_log, f, indent=2)
            with open(telemetry_file, 'w') as f:
                json.dump(telemetry_log, f, indent=2)
            print(f"‚úÖ Zapisano:")
            print(f"   Scoring:    {len(scoring_log)} rekord√≥w -> {scoring_file}")
            print(f"   Telemetry:  {len(telemetry_log)} rekord√≥w -> {telemetry_file}")
        else:
            print("‚ö†Ô∏è Brak rekord√≥w do zapisania")
        print(f"{'='*60}\n")


def preprocess_data(raw_vector_x, scaler_X_min_max, scaler_X_robust):
    """
    Skaluje pojedynczy wektor (37,), stosujƒÖc scaler tylko do 
    czƒô≈õci ciƒÖg≈Çej (0-19) i zostawiajƒÖc kategorialnƒÖ (20-36).
    """
    no_scaler_x = slice(0, 8)  # no scaler for X
    min_max_scaler_x = slice(8, 20)  # min-max scaler for X
    robust_scaler_x = slice(20, 28)  # robust scaler for X
    #POTEM JAK ZMIENIE NA NORM ENDET
    # no_scaler_x = slice(0, 9)  # no scaler for X
    # min_max_scaler_x = slice(9, 21)  # min-max scaler for X
    # robust_scaler_x = slice(21, 28)  # robust scaler for X
    
    # raw_vector_x[cont_indices_x] ma kszta≈Çt (19,)
    # Musimy go przekszta≈Çciƒá na (1, 19) dla scalera
    x_min_max_scaled = scaler_X_min_max.transform([raw_vector_x[min_max_scaler_x]])
    x_robust_scaled = scaler_X_robust.transform([raw_vector_x[robust_scaler_x]])
    
    # raw_vector_x[cat_indices_x] ma kszta≈Çt (18,)
    # --- POPRAWKA TUTAJ ---
    # Musimy go przekszta≈Çciƒá na (1, 19), aby pasowa≈Ç do hstack
    x_no_scaled = raw_vector_x[no_scaler_x].reshape(1, -1)
    
    # Teraz ≈ÇƒÖczymy (1, 19) z (1, 18) -> (1, 37)
    # i sp≈Çaszczamy z powrotem do 1D (37,)
    return np.hstack([x_no_scaled, x_min_max_scaled, x_robust_scaled]).flatten()


def filtr_data(telem_raw, scoring_raw):
    wanted_weather_keys = ["mRaining","mAmbientTemp","mTrackTemp","mEndET", "mCurrentET","mAvgPathWetness"]
    subset_weather = {k: scoring_raw.get(k) for k in wanted_weather_keys}
    subset_weather["mTotalLapDistance"] = scoring_raw["mLapDist"]

    wanted_keys = ["mLastLapTime","mBestLapTime","mCurrLapTime","mNumPitstops","mNumPenalties","mInPits","mFinishStatus","mLapDist","mSector","mTotalLaps"]
    vehicles = scoring_raw.get("mVehicles", [])
    
    player_vehicle = None
    for v in vehicles:
        if v.get("mIsPlayer") == True:
            player_vehicle = v
            break

    # ‚úÖ DODAJ SPRAWDZENIE
    if not player_vehicle:
        raise ValueError("‚ùå Nie znaleziono gracza w danych Scoring!")

    subset_scoring_vehicle = {k: player_vehicle.get(k) for k in wanted_keys}
    
    wanted_keys_telem = ["mFuel", "mFuelCapacity","mWheel","mDentSeverity","mFrontTireCompoundIndex","mCurrentSector","mLapNumber","mLastImpactET","mLastImpactMagnitude","multiplier","is_repairing"]
    subset_telem = {k: telem_raw.get(k) for k in wanted_keys_telem}

    filtered_data_scoring = {**subset_scoring_vehicle, **subset_weather}
    filtered_data_telemetry = subset_telem

    return filtered_data_telemetry, filtered_data_scoring
def extract_state(telem_file_raw, scoring_file_raw):
        filtered_data_telemetry, filtered_data_scoring = filtr_data(telem_file_raw,scoring_file_raw)
        data_state = []
        
        scoring = filtered_data_scoring
        telemetry = filtered_data_telemetry
        
        
        data_state_rl = [
            
            telemetry["mFuel"]/telemetry["mFuelCapacity"],
            scoring["mCurrentET"]/scoring["mEndET"],
            telemetry['mWheel'][0]['mWear'],  
            telemetry["mWheel"][1]["mWear"],
            telemetry["mWheel"][2]["mWear"],
            telemetry["mWheel"][3]["mWear"],
            scoring["mAvgPathWetness"],
            scoring["mRaining"],
            # round(scoring["mEndET"],5)/7200.0, potem jak zmienie na norm

            
            #MIN-MAX SCALER
            
            telemetry["mDentSeverity"][0],  # Not defined which part of the car this refers to each index
            telemetry["mDentSeverity"][1],
            telemetry["mDentSeverity"][2], 
            telemetry["mDentSeverity"][3],
            telemetry["mDentSeverity"][4],
            telemetry["mDentSeverity"][5],
            telemetry["mDentSeverity"][6], 
            telemetry["mDentSeverity"][7],
            scoring["mTotalLaps"],
            scoring["mNumPitstops"],
            telemetry["mFrontTireCompoundIndex"],
            telemetry["multiplier"],
            #ROUBST SCALER
            sum(telemetry["mWheel"][0]["mTemperature"])/len(telemetry["mWheel"][0]["mTemperature"]),
            sum(telemetry["mWheel"][1]["mTemperature"])/len(telemetry["mWheel"][1]["mTemperature"]),
            sum(telemetry["mWheel"][2]["mTemperature"])/len(telemetry["mWheel"][2]["mTemperature"]),
            sum(telemetry["mWheel"][3]["mTemperature"])/len(telemetry["mWheel"][3]["mTemperature"]),
            scoring["mAmbientTemp"],
            scoring["mTrackTemp"],
            round(scoring["mEndET"],5),
        ]



        return data_state_rl


def select_action_deterministic(model, state):
    """Wersja dla rzeczywistych wy≈õcig√≥w - wybiera najlepszƒÖ akcjƒô"""
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(device)

    with torch.no_grad():
        logits_list, _ = model(state_tensor)

    # DEBUG: Poka≈º surowe logity
    print(f"\nüîç DEBUG - Surowe logity modelu:")
    print(f"   Pit-stop logits: {logits_list[0].cpu().numpy()}")
    print(f"   Tire logits: {logits_list[1].cpu().numpy()}")
    print(f"   Repair logits: {logits_list[2].cpu().numpy()}")
    print(f"   Fuel logits: {logits_list[3].cpu().numpy()}")

    actions = []
    for logits in logits_list:
        # Najbardziej prawdopodobna akcja
        action = logits.squeeze(0).argmax()
        actions.append(action.item())

    return actions

def action_to_string(actions):
    """Zwraca zwiƒôz≈Çy string z akcjƒÖ"""
    if actions[0] == 0:
        return "Brak pit-stopu"
    pit = "Zjed≈∫ na pit-stop" if actions[0] == 1 else "Nie zje≈ºd≈ºaj"
    tire_names = ["Bez zmiany", "Miƒôkkie", "≈örednie", "Twarde", "Deszczowe"]
    repair = "Naprawa" if actions[2] == 1 else "Brak naprawy"
    fuel_pct = actions[3] * 20
    
    return f"{pit} | {tire_names[actions[1]]} | {repair} | Paliwo:{fuel_pct}%"

